{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import MeanShift, DBSCAN, estimate_bandwidth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(join('..', 'data', 'data_preprocessed.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>frq</th>\n",
       "      <th>rcn</th>\n",
       "      <th>mnt</th>\n",
       "      <th>clothes</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>small_appliances</th>\n",
       "      <th>toys</th>\n",
       "      <th>house_keeping</th>\n",
       "      <th>...</th>\n",
       "      <th>oh_status_Widow</th>\n",
       "      <th>oh_gender_M</th>\n",
       "      <th>oh_dependents_1.0</th>\n",
       "      <th>oh_description_Kind of OK</th>\n",
       "      <th>oh_description_Meh...</th>\n",
       "      <th>oh_description_OK nice!</th>\n",
       "      <th>oh_description_Take my money!!</th>\n",
       "      <th>PC0</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>0.743162</td>\n",
       "      <td>1.191605</td>\n",
       "      <td>0.457819</td>\n",
       "      <td>1402</td>\n",
       "      <td>-0.617023</td>\n",
       "      <td>-0.243065</td>\n",
       "      <td>1.216847</td>\n",
       "      <td>0.495837</td>\n",
       "      <td>-0.499274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.896356</td>\n",
       "      <td>-1.937697</td>\n",
       "      <td>1.120781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88</td>\n",
       "      <td>1.559488</td>\n",
       "      <td>1.100011</td>\n",
       "      <td>-1.535723</td>\n",
       "      <td>1537</td>\n",
       "      <td>0.166160</td>\n",
       "      <td>-0.790228</td>\n",
       "      <td>0.740464</td>\n",
       "      <td>-0.374374</td>\n",
       "      <td>-0.631907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.981092</td>\n",
       "      <td>-1.421498</td>\n",
       "      <td>0.785625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>-1.548542</td>\n",
       "      <td>-0.823463</td>\n",
       "      <td>0.557496</td>\n",
       "      <td>44</td>\n",
       "      <td>-0.834573</td>\n",
       "      <td>1.672006</td>\n",
       "      <td>-0.371096</td>\n",
       "      <td>-0.809480</td>\n",
       "      <td>2.286023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.813108</td>\n",
       "      <td>0.381440</td>\n",
       "      <td>-0.780867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69</td>\n",
       "      <td>0.845528</td>\n",
       "      <td>0.550447</td>\n",
       "      <td>-1.402820</td>\n",
       "      <td>888</td>\n",
       "      <td>0.383710</td>\n",
       "      <td>0.440889</td>\n",
       "      <td>-0.768082</td>\n",
       "      <td>-0.084304</td>\n",
       "      <td>-0.234007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.247013</td>\n",
       "      <td>-0.514177</td>\n",
       "      <td>-1.302203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69</td>\n",
       "      <td>0.782435</td>\n",
       "      <td>1.008417</td>\n",
       "      <td>-0.871209</td>\n",
       "      <td>1138</td>\n",
       "      <td>0.340200</td>\n",
       "      <td>-0.243065</td>\n",
       "      <td>-0.053508</td>\n",
       "      <td>-0.374374</td>\n",
       "      <td>-0.366640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.781920</td>\n",
       "      <td>-0.704805</td>\n",
       "      <td>-0.443376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age    income       frq       rcn   mnt   clothes   kitchen  \\\n",
       "0   78  0.743162  1.191605  0.457819  1402 -0.617023 -0.243065   \n",
       "1   88  1.559488  1.100011 -1.535723  1537  0.166160 -0.790228   \n",
       "2   34 -1.548542 -0.823463  0.557496    44 -0.834573  1.672006   \n",
       "3   69  0.845528  0.550447 -1.402820   888  0.383710  0.440889   \n",
       "4   69  0.782435  1.008417 -0.871209  1138  0.340200 -0.243065   \n",
       "\n",
       "   small_appliances      toys  house_keeping  ...  oh_status_Widow  \\\n",
       "0          1.216847  0.495837      -0.499274  ...              0.0   \n",
       "1          0.740464 -0.374374      -0.631907  ...              0.0   \n",
       "2         -0.371096 -0.809480       2.286023  ...              0.0   \n",
       "3         -0.768082 -0.084304      -0.234007  ...              0.0   \n",
       "4         -0.053508 -0.374374      -0.366640  ...              0.0   \n",
       "\n",
       "   oh_gender_M oh_dependents_1.0 oh_description_Kind of OK  \\\n",
       "0          1.0               0.0                       0.0   \n",
       "1          0.0               0.0                       0.0   \n",
       "2          1.0               1.0                       1.0   \n",
       "3          0.0               1.0                       0.0   \n",
       "4          0.0               1.0                       0.0   \n",
       "\n",
       "  oh_description_Meh... oh_description_OK nice!  \\\n",
       "0                   0.0                     0.0   \n",
       "1                   0.0                     0.0   \n",
       "2                   0.0                     0.0   \n",
       "3                   0.0                     1.0   \n",
       "4                   0.0                     0.0   \n",
       "\n",
       "   oh_description_Take my money!!       PC0       PC1       PC2  \n",
       "0                             1.0  0.896356 -1.937697  1.120781  \n",
       "1                             1.0  1.981092 -1.421498  0.785625  \n",
       "2                             0.0 -2.813108  0.381440 -0.780867  \n",
       "3                             0.0  1.247013 -0.514177 -1.302203  \n",
       "4                             1.0  1.781920 -0.704805 -0.443376  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'income', 'frq', 'rcn', 'mnt', 'clothes', 'kitchen',\n",
       "       'small_appliances', 'toys', 'house_keeping', 'dependents',\n",
       "       'per_net_purchase', 'gender', 'education', 'status', 'description',\n",
       "       'birth_year', 'spent_online', 'oh_education_2nd Cycle',\n",
       "       'oh_education_Graduation', 'oh_education_Master', 'oh_education_PhD',\n",
       "       'oh_status_Married', 'oh_status_Single', 'oh_status_Together',\n",
       "       'oh_status_Widow', 'oh_gender_M', 'oh_dependents_1.0',\n",
       "       'oh_description_Kind of OK', 'oh_description_Meh...',\n",
       "       'oh_description_OK nice!', 'oh_description_Take my money!!', 'PC0',\n",
       "       'PC1', 'PC2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting feature names into groups\n",
    "# Remember which metric_features we decided to keep?\n",
    "metric_features = ['income',\n",
    " 'frq',\n",
    " 'rcn',\n",
    " 'clothes',\n",
    " 'kitchen',\n",
    " 'small_appliances',\n",
    " 'toys',\n",
    " 'house_keeping',\n",
    " 'per_net_purchase',\n",
    " 'spent_online']\n",
    "\n",
    "non_metric_features = df.columns[df.columns.str.startswith('oh_')].tolist() # CODE HERE\n",
    "pc_features = df.columns[df.columns.str.startswith('PC')].tolist()  # CODE HERE\n",
    "\n",
    "unused_features = [i for i in df.columns if i not in (metric_features+non_metric_features+pc_features) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric_features: ['income', 'frq', 'rcn', 'clothes', 'kitchen', 'small_appliances', 'toys', 'house_keeping', 'per_net_purchase', 'spent_online']\n",
      "\n",
      "non_metric_features: ['oh_education_2nd Cycle', 'oh_education_Graduation', 'oh_education_Master', 'oh_education_PhD', 'oh_status_Married', 'oh_status_Single', 'oh_status_Together', 'oh_status_Widow', 'oh_gender_M', 'oh_dependents_1.0', 'oh_description_Kind of OK', 'oh_description_Meh...', 'oh_description_OK nice!', 'oh_description_Take my money!!']\n",
      "\n",
      "unused_features: ['age', 'mnt', 'dependents', 'gender', 'education', 'status', 'description', 'birth_year']\n",
      "\n",
      "pc_features: ['PC0', 'PC1', 'PC2']\n"
     ]
    }
   ],
   "source": [
    "print('metric_features:', metric_features)\n",
    "print('\\nnon_metric_features:', non_metric_features)\n",
    "print('\\nunused_features:', unused_features)\n",
    "print('\\npc_features:', pc_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ss(df):\n",
    "    \"\"\"Computes the sum of squares for all variables given a dataset\n",
    "    \"\"\"\n",
    "    ss = np.sum(df.var() * (df.count() - 1))\n",
    "    return ss  # return sum of sum of squares of each df variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density Based Clustering\n",
    "## Mean Shift Clustering\n",
    "What is Mean-shift clustering? How does it work?\n",
    "\n",
    "Single seed             |  Multiple seeds\n",
    ":-------------------------:|:-------------------------:\n",
    "![](../figures/clustering/mean_shift_0.gif)  |  ![](../figures/clustering/mean_shift_tutorial.gif)\n",
    " \n",
    "### Characteristics:\n",
    "- No need to define number of clusters apriori\n",
    "- Can detect clusters of any shape\n",
    "- Robust to outliers\n",
    "- Depends on the bandwidth hyperparameter (but there's a way to estimate it)\n",
    "- **Main drawback**: Poor scalability (on both the algorithm and in estimating the bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.85008088861608"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following bandwidth can be automatically detected using \n",
    "# # (we need to set quantile though)\n",
    "# Based on distance to nearest neighbors for all observations\n",
    "\n",
    "bandwidth = estimate_bandwidth(df[metric_features], \n",
    "# TO-DO: manipulate the quantile value such that we obtain a small enough bandwidth\n",
    "                               quantile=0.9, # \n",
    "                               random_state=1, \n",
    "                               n_jobs=-1)\n",
    "bandwidth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does `estimate_bandwidth` work?\n",
    "\n",
    "https://scikit-learn.org/1.5/modules/generated/sklearn.cluster.estimate_bandwidth.html#sklearn.cluster.estimate_bandwidth\n",
    "\n",
    "Code from https://github.com/scikit-learn/scikit-learn/blob/6e9039160/sklearn/cluster/_mean_shift.py#L43\n",
    "\n",
    "```python\n",
    "    \n",
    "    n_neighbors = int(X.shape[0] * quantile)\n",
    "    if n_neighbors < 1:  # cannot fit NearestNeighbors with n_neighbors = 0\n",
    "        n_neighbors = 1\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors, n_jobs=n_jobs)\n",
    "    nbrs.fit(X)\n",
    "\n",
    "    bandwidth = 0.0\n",
    "    for batch in gen_batches(len(X), 500):\n",
    "        d, _ = nbrs.kneighbors(X[batch, :], return_distance=True)\n",
    "        bandwidth += np.max(d, axis=1).sum()\n",
    "\n",
    "    return bandwidth / X.shape[0]\n",
    "```\n",
    "\n",
    "\n",
    "1. Specify `quantile`: \n",
    "    - Determines `n_neighbors`, which is how many neighbors to include when computing distances\n",
    "2. Divide data into batches (for efficient calculation)\n",
    "3. For each point, calculate `n_neighbors` Nearest Neighbors.\n",
    "4. Get the largest distance to the `n_neighbors`\n",
    "5. Get the average of these largest distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Shift Algorithm, changing bandwidth values by modifying quantile values:\n",
    "\n",
    "![](../figures/clustering/ms_quantile_bandwidth.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Shift Algorithm, showing initial and final locations of seeds with varying bandwidth values.\n",
    "\n",
    "![](../figures/clustering/ms_q_bw_start_end.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of estimated clusters : 1\n"
     ]
    }
   ],
   "source": [
    "# Perform mean-shift clustering with bandwidth set using estimate_bandwidth\n",
    "# TO-DO: explore the MeanShift class and obtain the cluster labels\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html#sklearn.cluster.MeanShift\n",
    "\n",
    "ms = MeanShift()\n",
    "ms_labels = None\n",
    "\n",
    "ms_n_clusters = len(np.unique(ms_labels))\n",
    "print(\"Number of estimated clusters : %d\" % ms_n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>frq</th>\n",
       "      <th>rcn</th>\n",
       "      <th>clothes</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>small_appliances</th>\n",
       "      <th>toys</th>\n",
       "      <th>house_keeping</th>\n",
       "      <th>per_net_purchase</th>\n",
       "      <th>spent_online</th>\n",
       "      <th>ms_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.743162</td>\n",
       "      <td>1.191605</td>\n",
       "      <td>0.457819</td>\n",
       "      <td>-0.617023</td>\n",
       "      <td>-0.243065</td>\n",
       "      <td>1.216847</td>\n",
       "      <td>0.495837</td>\n",
       "      <td>-0.499274</td>\n",
       "      <td>-1.257560</td>\n",
       "      <td>0.522055</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.559488</td>\n",
       "      <td>1.100011</td>\n",
       "      <td>-1.535723</td>\n",
       "      <td>0.166160</td>\n",
       "      <td>-0.790228</td>\n",
       "      <td>0.740464</td>\n",
       "      <td>-0.374374</td>\n",
       "      <td>-0.631907</td>\n",
       "      <td>-1.798649</td>\n",
       "      <td>-0.237578</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.548542</td>\n",
       "      <td>-0.823463</td>\n",
       "      <td>0.557496</td>\n",
       "      <td>-0.834573</td>\n",
       "      <td>1.672006</td>\n",
       "      <td>-0.371096</td>\n",
       "      <td>-0.809480</td>\n",
       "      <td>2.286023</td>\n",
       "      <td>0.906799</td>\n",
       "      <td>-0.904191</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.845528</td>\n",
       "      <td>0.550447</td>\n",
       "      <td>-1.402820</td>\n",
       "      <td>0.383710</td>\n",
       "      <td>0.440889</td>\n",
       "      <td>-0.768082</td>\n",
       "      <td>-0.084304</td>\n",
       "      <td>-0.234007</td>\n",
       "      <td>-0.391816</td>\n",
       "      <td>0.785568</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.782435</td>\n",
       "      <td>1.008417</td>\n",
       "      <td>-0.871209</td>\n",
       "      <td>0.340200</td>\n",
       "      <td>-0.243065</td>\n",
       "      <td>-0.053508</td>\n",
       "      <td>-0.374374</td>\n",
       "      <td>-0.366640</td>\n",
       "      <td>-0.445925</td>\n",
       "      <td>1.237135</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     income       frq       rcn   clothes   kitchen  small_appliances  \\\n",
       "0  0.743162  1.191605  0.457819 -0.617023 -0.243065          1.216847   \n",
       "1  1.559488  1.100011 -1.535723  0.166160 -0.790228          0.740464   \n",
       "2 -1.548542 -0.823463  0.557496 -0.834573  1.672006         -0.371096   \n",
       "3  0.845528  0.550447 -1.402820  0.383710  0.440889         -0.768082   \n",
       "4  0.782435  1.008417 -0.871209  0.340200 -0.243065         -0.053508   \n",
       "\n",
       "       toys  house_keeping  per_net_purchase  spent_online  ms_labels  \n",
       "0  0.495837      -0.499274         -1.257560      0.522055        NaN  \n",
       "1 -0.374374      -0.631907         -1.798649     -0.237578        NaN  \n",
       "2 -0.809480       2.286023          0.906799     -0.904191        NaN  \n",
       "3 -0.084304      -0.234007         -0.391816      0.785568        NaN  \n",
       "4 -0.374374      -0.366640         -0.445925      1.237135        NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenating the labels to df\n",
    "df_concat = pd.concat([df[metric_features], pd.Series(ms_labels, index=df.index, name=\"ms_labels\")], axis=1)\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cb/8gnf1rrd7914vbmqtgrt2mmm0000gn/T/ipykernel_52733/1419269472.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ssw_labels = df_concat.groupby(by='ms_labels').apply(get_ss)  # compute ssw for each cluster labels\n",
      "/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/numpy/core/fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot convert the series to <class 'float'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m ssb \u001b[38;5;241m=\u001b[39m sst \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39msum(ssw_labels)  \u001b[38;5;66;03m# remember: SST = SSW + SSB\u001b[39;00m\n\u001b[1;32m      5\u001b[0m r2 \u001b[38;5;241m=\u001b[39m ssb \u001b[38;5;241m/\u001b[39m sst\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCluster solution with R^2 of \u001b[39;49m\u001b[38;5;132;43;01m%0.4f\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mr2\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/pandas/core/series.py:248\u001b[0m, in \u001b[0;36m_coerce_method.<locals>.wrapper\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconverter\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on a single element Series is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will raise a TypeError in the future. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    246\u001b[0m     )\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m converter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot convert the series to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconverter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot convert the series to <class 'float'>"
     ]
    }
   ],
   "source": [
    "# Computing the R^2 of the cluster solution\n",
    "sst = get_ss(df[metric_features])  # get total sum of squares\n",
    "ssw_labels = df_concat.groupby(by='ms_labels').apply(get_ss)  # compute ssw for each cluster labels\n",
    "ssb = sst - np.sum(ssw_labels)  # remember: SST = SSW + SSB\n",
    "r2 = ssb / sst\n",
    "print(\"Cluster solution with R^2 of %0.4f\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN (Density-based spatial clustering of applications with noise)\n",
    "What is DBSCAN clustering? How does it work?\n",
    "\n",
    "DBSCAN animation            |  Core, border and noise\n",
    ":-------------------------:|:-------------------------:\n",
    "![](../figures/clustering/dbscan.gif)  |  ![](../figures/clustering/dbscan.jpg)\n",
    "\n",
    "\n",
    "### Characteristics:\n",
    "- No need to define number of clusters apriori\n",
    "- Resistant to noise and outliers\n",
    "- Can identify outliers\n",
    "- Can handle clusters of different shapes and sizes\n",
    "- Depends highly on the epsilon hyperparameter and it can be hard to tune\n",
    "- Does not work well with clusters of varying densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform DBSCAN clustering\n",
    "# TO-DO: explore the DBSCAN class and obtain the cluster labels\n",
    "dbscan = DBSCAN()\n",
    "dbscan_labels = None \n",
    "\n",
    "dbscan_n_clusters = len(np.unique(dbscan_labels))\n",
    "print(\"Number of estimated clusters : %d\" % dbscan_n_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN Algorithm, varying epsilon and minpts values:\n",
    "\n",
    "*Square markers are noise points* \n",
    "\n",
    "![](../figures/clustering/dbscan_eps_minpts.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining eps and min_samples:\n",
    "- **MinPts**: As a rule of thumb, **minPts = 2 x dim** can be used, but it may be necessary to choose larger values for very large data, for noisy data or for data that contains many duplicates.\n",
    "\n",
    "- **Îµ**: The value for Îµ can then be chosen by using a **k-distance graph**, plotting the distance to the kth (k = minPts - 1) nearest neighbor ordered from the largest to the smallest value. Good values of Îµ are where this plot shows an **\"elbow\"**: if Îµ is chosen much too small, a large part of the data will not be clustered; whereas for a too high value of Îµ, clusters will merge and the majority of objects will be in the same cluster. \n",
    "\n",
    "- The assumption is that for points in a cluster, **their k nearest neighbors are at roughly the same distance**. Noise points have their k-th nearest neighbors at farther distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-distance graph to find out the right eps value\n",
    "neigh = NearestNeighbors(n_neighbors=20)\n",
    "neigh.fit(df[metric_features])\n",
    "distances, _ = neigh.kneighbors(df[metric_features])\n",
    "distances = np.sort(distances[:, -1])\n",
    "plt.plot(distances)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the labels to df\n",
    "df_concat = pd.concat([df[metric_features], pd.Series(dbscan_labels, index=df.index, name=\"dbscan_labels\")], axis=1)\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting noise (potential outliers)\n",
    "# TO-DO: can we identify the noisy data? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the R^2 of the cluster solution\n",
    "df_nonoise = df_concat.loc[df_concat['dbscan_labels'] != -1]\n",
    "sst = get_ss(df[metric_features])  # get total sum of squares\n",
    "ssw_labels = df_nonoise.groupby(by='dbscan_labels').apply(get_ss)  # compute ssw for each cluster labels\n",
    "ssb = sst - np.sum(ssw_labels)  # remember: SST = SSW + SSB\n",
    "r2 = ssb / sst\n",
    "print(\"Cluster solution with R^2 of %0.4f\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why did the DBSCAN gave us just one cluster?\n",
    "- What can we do with the noisy data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM (Gaussian Mixture Model )\n",
    "\n",
    "What is GMM? How does it work?\n",
    "\n",
    "![](../figures/clustering/gmm.gif)\n",
    "\n",
    "--- \n",
    "\n",
    "$$\\mathcal{p(\\vec{x})} \\ = \\ \\sum_{i=1}^K \\phi_i \\mathcal{N}(\\vec{x}|\\vec{\\mu_i}, \\Sigma_i) \\tag{eq1}$$\n",
    "$$\\mathcal{N}(\\vec{x}|\\vec{\\mu_i}, \\Sigma_i) \\ = \\ \\frac{1}{\\sqrt{{(2\\pi)}^{K}|\\Sigma_i|}}e^{-\\frac{1}{2} (\\vec{x} - \\vec{\\mu_i})^T \\Sigma_i^{-1} (\\vec{x} - \\vec{\\mu_i})} \\tag{eq2}$$\n",
    "$$\\sum_{i=1}^K \\phi_i \\ = \\ 1 \\tag{eq3}$$\n",
    "\n",
    ", where:\n",
    "- $\\phi_i$ is the component weight (scalar) for Component $i$ (probability of an observation being generated by Component $i$)\n",
    "- $\\vec{\\mu_i}$ is the mean vector for Component $i$,\n",
    "- $\\Sigma_i$ is the Covariance matrix for Component $i$\n",
    "\n",
    "---\n",
    "\n",
    "- **(eq1)** gives the probability of a point $x$ given the estimated Gaussian mixture\n",
    "- **(eq2)** is the probability density function of a multivariate Gaussian with mean $\\vec{\\mu_i}$ and covariance $\\Sigma_i$\n",
    "- **(eq3)** states that the sum of the component weights is 1, such that the total probability distribution normalizes to 1\n",
    "\n",
    "### Characteristics:\n",
    "- Assumes the data is generated from a mixture of finite number of Gaussian distributions with unknown parameters\n",
    "- Use the EM (Expectation Maximization algorithm) to estimate the parameters\n",
    "- Provides a probability of each observation belonging to each cluster\n",
    "- Advantages over K-Means:\n",
    "    - Can deal with spherical and elipsoid cluster shapes\n",
    "    - Number of components needs to be defined apriori\n",
    "    \n",
    "\n",
    "[Read More](https://jakevdp.github.io/PythonDataScienceHandbook/05.12-gaussian-mixtures.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing GMM clustering\n",
    "# https://scikit-learn.org/1.5/modules/generated/sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture\n",
    "\n",
    "gmm = GaussianMixture(n_components=4, \n",
    "                      covariance_type='full', \n",
    "                      n_init=10, \n",
    "                      init_params='kmeans', \n",
    "                      random_state=1)\n",
    "gmm_labels = gmm.fit_predict(df[metric_features])\n",
    "labels_proba = gmm.predict_proba(df[metric_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's look at the estimated parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The estimated component weights\n",
    "gmm.weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The estimated mean vectors of the Components\n",
    "print(gmm.means_.shape)\n",
    "gmm.means_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The estimated covariance matrices of the Components\n",
    "gmm.covariances_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining covariance_type:\n",
    "This hyperparameter controls the **degrees of freedom** in the shape of each cluster The more degrees of freedom we have the more complex shapes the model can fit and the more computationally expensive the model will be.\n",
    "\n",
    "![](../figures/clustering/gmm_covariance.png)\n",
    "\n",
    "- `covariance_type=\"tied\"` makes all components share the same general covariance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figures/clustering/gmm_components_covars.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining n_components:\n",
    "\n",
    "**AIC**: estimates the relative amount of information lost by a model used to represent the data-generation process. The smaller the better.\n",
    "\n",
    "**BIC**: similar to AIC but penalizes more complex models (i.e. favors simpler models). The smaller the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may take a while to run\n",
    "# \n",
    "# Selecting number of components based on AIC and BIC\n",
    "n_components = np.arange(1, 16)\n",
    "models = [GaussianMixture(n, covariance_type='full', n_init=10, random_state=1).fit(df[metric_features])\n",
    "          for n in n_components]\n",
    "\n",
    "bic_values = [m.bic(df[metric_features]) for m in models]\n",
    "aic_values = [m.aic(df[metric_features]) for m in models]\n",
    "plt.plot(n_components, bic_values, label='BIC')\n",
    "plt.plot(n_components, aic_values, label='AIC')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('n_components')\n",
    "plt.xticks(n_components)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: the AIC and BIC measures can also be used to select diferent hyperparameters such as the covariance_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing GMM clustering\n",
    "gmm = GaussianMixture(n_components=3, covariance_type='full', n_init=10, init_params='kmeans', random_state=1)\n",
    "gmm_labels = gmm.fit_predict(df[metric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the labels to df\n",
    "df_concat = pd.concat([df[metric_features], pd.Series(gmm_labels, index=df.index, name=\"gmm_labels\")], axis=1)\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the R^2 of the cluster solution\n",
    "sst = get_ss(df[metric_features])  # get total sum of squares\n",
    "ssw_labels = df_concat.groupby(by='gmm_labels').apply(get_ss)  # compute ssw for each cluster labels\n",
    "ssb = sst - np.sum(ssw_labels)  # remember: SST = SSW + SSB\n",
    "r2 = ssb / sst\n",
    "print(\"Cluster solution with R^2 of %0.4f\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering by Perspectives\n",
    "- Demographic Perspective:\n",
    "- Value Perspective:\n",
    "- Product Perspective:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the Perspectives\n",
    "- How can we merge different cluster solutions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2425",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
